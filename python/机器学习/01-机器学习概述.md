# 人工智能概述

## 1. 人工智能三大概述

### 1.1 人工智能 AI / 机器学习 ML / 深度学习 DL 三者关系

机器学习是实现人工智能的一种途径,深度学习是机器学习的一种方法发展而来

目前的人工智能技术体系

- 基于统计学的传统机器学习方法
- 基于神经网络的深度学习方法

### 1.2 样本 / 特征 / 标签

- 样本( sample )
  - 一行数据就是一个样本; 多个样本组成数据集; 有时一条样本也叫做一条记录
- 特征 ( feature )
  - 一列数据一个特征, 有时也叫做属性
- 标签 / 目标 ( label / target )
  - 模型要预测的那一列
- 特征如何理解(重点)
  - 特征就从数据中抽取出来的,对结果预测有用的信息, 如: 房价预测  车图片识别等

### 1.3 数据集划分

数据集可划分为两部分: 训练集   测试集  比例 8:2 ( 常用 )  / 7:3

- 训练集 (tarining set) : 用来训练模型 (model) 数据集
- 测试集 (testing set) : 用来测试模型的数据集

---

## 2. 机器学习算法分类

- 监督性学习  supervised Learning

  - 输入数据是由输入特征值和目标值所组成,即输入的训练数据有标签的

  - 数据集: 需要表述数据的标签 / 目标值

  - 有监督分类问题 & 回归问题

    - 分类问题
      - 目标值(标签值) 是不连续的
      - 分类种类: 二分类 多分类
    - 回归问题
      - 目标值(标签值)是连续的
- 无监督性学习 unSuperised Learning

  - 输入没有被标记,即样本的数据类别未知,没有标签,根据样本件的相似性,对样本聚集类,以发现事务内部结构及相互关系
- 半监督学习  Semi Supervised Learning

  - 工作原理
    - 让专家标注少量数据,利用已经标注的数据( 也就是带有类标签 ) 训练出一个模型
    - 再利用模型去套用未标记的数据
    - 通过询问领域专家分类结果与模型分类结果对比,从而对模型做进一步改善和提高
  -   优点: 半监督学习方式可大幅度降低标注成本,常用语数据标注场景
- 强化学习 Reinforcement Learning
  - 强化学习: 机器学习的一个重要分支
  - 应用场景: AlphaGo 各类游戏 对抗比赛  无人驾驶等
  - 基本原理:
    - 通过构建四个元素 Agent , 环境状态(State) , 行动(Action) , 奖励(Reward)
    - Agent 根据环境状态进行行动获得最多的累计奖励

  - 举例: 小孩学走路
    - 小孩 (Agent) 试图通过**采取行动**(行走),在**操作环境**(行走的表现)
    - 并且从一个状态转变到另一个状态(即他走的每一步)
    - 当他完成任务的子任务(即走了几步)时, 孩子得到**奖励(**巧克力)
    - 并且当他不能走路时,就不会给巧克力


---

##   3. 线性回归--模型训练推理

```python
# 导包  LinearRegression 为线性回归模型
from sklearn.linear_model import LinearRegression
import joblib

# 创建模型训练 & 保存模型
def create_demo01():
    # 准备数据 平时成绩 期末成绩 最终成绩
    x = [[80,86],[82,80],[85,78],[90,90],[86,82],[82,90],[78,80],[92,94]]
    y = [84.2,80.6,80.1,90,83.2,87.6,79.4,93.4]
    
    # 实例化 线性回归模型
    regression = LinearRegression()
    print("实例化线性回归模型",regression)
    
    # 模型训练
    # 打印线性回归模型参数 coef_  intercept_
    regression.fit(x,y)
    print("regression.coef[斜率]--->",regression.coef_)
    print("regression.intercept[偏置]--->",regression.intercept_)
	
    # 模型推理
    # mypered = regression.predict([[90,80]])
    # print('mypered',mypered )
    
    # 模型保存
    joblib.dump(regression,'./module/create_demo01.bin')

# 调用保存好的模型    
def handle_module():
    # 加载模型
    regression2 = joblib.load("./module/craete_demo01.bin")
    mypred2 = regression2.predict([[90,80]])
    print("斜率",mypred2.coef_)
    print("偏置",mypred2.intercept_)
    print("推理结果",myred2)
    
if __name__ = "__main__":
    # 调用模型训练函数
    create_demo01()
    # 调用模型推理函数
    handle_module()
```

## 4. KNN--模型训练推理

```python
# 导包
from slearn.neignbors import KNeighborsClassifier

def create_demo2():
   	# 搞笑镜头  拥抱镜头  打斗镜头 
    x = [[39,0,31],[3,2,65],[2,3,55],[9,38,2],[8,34,17],[5,2,57],[21,17,5],[45,2,9]]
    # 喜剧片 动作片 爱情片
    y = [0,1,2,2,2,1,0,0]
    
    # 实例化 KNN 模型
    estimator = KNeighborsClassifier(n_neighbors=3)
    print("estimator knn",estimator)
    
    # 模型训练
    estimator.fit(x,y)
    
    # 模型推理
    mypre = estimator.predict([[23,3,17]])
    print("推理结果",mypre)
    
if __name__ == "__main__":
    create_demo2() // [0] 喜剧片
```

| 部分                   | 含义                                                         |
| ---------------------- | ------------------------------------------------------------ |
| `KNeighborsClassifier` | **K 近邻分类器**（K-Nearest Neighbors Classifier）           |
| `n_neighbors=3`        | **只找离新样本最近的 3 个训练点**，然后“投票”决定新样本的类别 |

### 工作流程（极简版）

1. 训练时：它只是**把数据存起来**，不学参数。
2. 预测时：
   - 算新样本到所有训练点的距离（默认欧氏距离）。
   - 找出最近的 3 个邻居。
   - 这 3 个邻居里哪种标签多，新样本就判为哪一类。

总结:

`KNeighborsClassifier(n_neighbors=3)` 就是 **“找 3 个最近邻居投票决定类别”** 的懒人分类器。